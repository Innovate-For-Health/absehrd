{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABSEHRD package demo\n",
    "This notebook demonstrates Automated Brewering Synthetic Electronic Health Record Data (ABSEHRD) package functionality on a toy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python and ABSEHRD modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocessor import Preprocessor\n",
    "from corgan import Corgan\n",
    "from realism import Realism\n",
    "from privacy import Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters for the toy dataset and demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy dataset\n",
    "n = 10000\n",
    "count_min = 5\n",
    "count_max = 19\n",
    "constant_value = 'helloworld'\n",
    "binary_A = 'A'\n",
    "binary_B = 'B'\n",
    "categorical_values = ['X','Y','Z']\n",
    "missing_value = -99999\n",
    "\n",
    "# synthetic data generation and validation\n",
    "n_gen = round(n/2)\n",
    "outcome = 'binary01'\n",
    "\n",
    "# sehrd objects\n",
    "pre = Preprocessor(missing_value=missing_value)\n",
    "rea = Realism()\n",
    "pri = Privacy()\n",
    "cor = Corgan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['helloworld' '1' 'A' 'Y' '14' '0.24115798945101719']\n",
      " ['helloworld' '1' 'A' 'X' '16' '0.7739167315409661']\n",
      " ['helloworld' '1' 'A' 'Z' '13' '0.733591719689214']\n",
      " ...\n",
      " ['helloworld' '1' 'A' 'X' '8' '0.15631542580525104']\n",
      " ['helloworld' '0' 'A' 'X' '10' '0.4571789089675996']\n",
      " ['helloworld' '1' 'B' 'Z' '12' '0.937723003397054']]\n"
     ]
    }
   ],
   "source": [
    "names = np.array(['constant','binary01', 'binaryAB', 'categorical','count','continuous'])\n",
    "v_constant = np.full(shape=n, fill_value=constant_value)\n",
    "v_binary01 = np.random.randint(low=0, high=2, size=n)\n",
    "v_binaryAB = np.concatenate((np.full(shape=n-1, fill_value=binary_A), np.array([binary_B])))\n",
    "v_categorical = np.random.choice(categorical_values, size=n)\n",
    "v_count = np.random.randint(low=count_min, high=count_max+1, size=n)\n",
    "v_continuous = np.random.random(size=n)\n",
    "x = np.column_stack((v_constant, v_binary01, v_binaryAB, v_categorical, v_count, v_continuous))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5000\n",
      "Number of testing samples: 5000\n"
     ]
    }
   ],
   "source": [
    "n_subset = round(len(x) * 0.5)\n",
    "idx_trn = np.random.choice(len(x), n_subset, replace=False)\n",
    "idx_tst = np.setdiff1d(range(len(x)), idx_trn)\n",
    "x_trn = x[idx_trn,:]\n",
    "x_tst = x[idx_tst,:]\n",
    "\n",
    "print('Number of training samples: '+str(len(x_trn)))\n",
    "print('Number of testing samples: '+str(len(x_tst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metadata for restoring data format after synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_name, var_type, min, max, zero, one, unique, missing\n",
      "[('constant', 'constant', 0.00000000e+00,  0.        , 'helloworld', '', '', False)\n",
      " ('binary01', 'binary', 0.00000000e+00,  0.        , '0', '1', '', False)\n",
      " ('binaryAB', 'binary', 0.00000000e+00,  0.        , 'A', 'B', '', False)\n",
      " ('categorical', 'categorical', 0.00000000e+00,  0.        , '', '', 'X,Y,Z', False)\n",
      " ('count', 'count', 5.00000000e+00, 19.        , '', '', '', False)\n",
      " ('continuous', 'continuous', 5.41996356e-05,  0.99936697, '', '', '', False)]\n"
     ]
    }
   ],
   "source": [
    "meta = pre.get_metadata(arr=x_trn, header=names)\n",
    "print('var_name, var_type, min, max, zero, one, unique, missing')\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode raw data matrix in preparation for training synthetic data generator\n",
    "Note that count and continuous variables have been scaled between 0 and 1 while constant, categorical, and binary have been one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted matrix:\n",
      "[[0.         0.         0.         ... 0.         0.48734487 0.        ]\n",
      " [0.         0.         1.         ... 0.         0.48557903 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.3206077  0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.46792516 0.        ]\n",
      " [0.         0.         1.         ... 0.         0.1298717  0.        ]\n",
      " [0.         0.         1.         ... 0.         0.28453527 0.        ]]\n",
      "\n",
      "Header for formatted matrix:\n",
      "['constant__constant' 'constant__-99999' 'binary01__binary01'\n",
      " 'binary01__-99999' 'binaryAB__binaryAB' 'binaryAB__-99999'\n",
      " 'categorical__0' 'categorical__1' 'categorical__2' 'categorical__3'\n",
      " 'count__count' 'count__-99999' 'continuous__continuous'\n",
      " 'continuous__-99999']\n"
     ]
    }
   ],
   "source": [
    "d_trn = pre.get_discretized_matrix(x_trn, meta, names)\n",
    "print('Formatted matrix:')\n",
    "print(d_trn['x'])\n",
    "print('\\nHeader for formatted matrix:')\n",
    "print(d_trn['header'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CorGAN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training: 100%|██████████| 100/100 [00:10<00:00,  9.77 epochs/s, [A loss: 1.041]]\n",
      "Training:  90%|█████████ | 90/100 [00:37<00:04,  2.39 epochs/s, TRAIN: [Loss_D: -0.009] [Loss_G: 0.012] [Loss_D_real: 0.019] [Loss_D_fake 0.010] | TEST: [A loss: 1.04] [real accuracy: 95.90] [fake accuracy: 23.44]]   "
     ]
    }
   ],
   "source": [
    "model = cor.train(x=d_trn['x'], n_cpu=1, debug=True, n_epochs_pretrain=100, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cor.generate(model, n_gen)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use metadata to restore original formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pre.restore_matrix(arr=s, meta=meta, header=d_trn['header'])\n",
    "print('Synthetic samples:')\n",
    "print(f['x'])\n",
    "print('\\nReal samples:')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare univariate frequency for real and synthetic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_frq = rea.feature_frequency(mat_f_r_trn=x_trn, \n",
    "                                mat_f_r_tst=x_tst, \n",
    "                                mat_f_s=f['x'], \n",
    "                                header=names, \n",
    "                                missing_value=missing_value)\n",
    "print(rea.summarize(res_frq))\n",
    "res_plt = rea.plot(res_frq, labels_on=True)\n",
    "res_plt = rea.plot(res_frq, labels_on=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare effect sizes\n",
    "Compare effect sizes from a train logistic regression method for a binary outcome between a model trained from real data and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_effect = rea.feature_effect(mat_f_r_trn=x_trn, \n",
    "                                mat_f_r_tst=x_tst, \n",
    "                                mat_f_s=f['x'], \n",
    "                                header=names, \n",
    "                                outcome=outcome, \n",
    "                                missing_value=missing_value, \n",
    "                                scaled=False)\n",
    "print(rea.summarize(res_effect))\n",
    "res_plt = rea.plot(res_effect, labels_on=True)\n",
    "res_plt = rea.plot(res_effect, labels_on=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare predictive performance\n",
    "* Real: use real dataset to train predictive model and test on a separate real dataset\n",
    "* GAN-train: use synthetic dataset to train predictive model and test on a real dataset\n",
    "*GAN-test: use real dataset to train predictive model and test on the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train models to predict outcome \\'', outcome,'\\' from real and synthetic datasets', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gan = rea.gan_train_test(mat_f_r_trn=x_trn, \n",
    "                                mat_f_r_tst=x_tst, \n",
    "                                mat_f_s=f['x'], \n",
    "                                header=names, \n",
    "                                outcome=outcome, \n",
    "                                missing_value=missing_value, \n",
    "                                n_epoch=100, \n",
    "                                model_type='mlp')\n",
    "print(rea.summarize(res_gan))\n",
    "res_plt = rea.plot(res_gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbors\n",
    "Ensure that synthetic dataset is not a copy of the real dataset by comparing distances between pairs of real and synthetic samples\n",
    "* Real-real: distance between randomly selected pairs of real samples\n",
    "* Real-synthetic: distance between pairs of real and synthetic samples\n",
    "* Real-probabilistic: distance between a real sample and sampled binary vector where each column is sampled from a binomial where the frequency equals that in the real training set\n",
    "* Real-random: distance between a real sample and a randomly sampled binary vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate, summarize, and plot nearest neighbor distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_nn = pri.assess_memorization(x_trn, \n",
    "                                 f['x'], \n",
    "                                 missing_value=missing_value, \n",
    "                                 header=names,\n",
    "                                 metric='euclidean',\n",
    "                                 debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pri.summarize(res_nn))\n",
    "res_plt = pri.plot(res_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership inference\n",
    "Membership inference refers to the ability to determine if a given data sample was used to train a model of interest.  In the case of synthetic data, calculating the risk of accurate membership inference given a sample of synthetic data can provide a metric to assess risk to privacy of the synthetic dataset to individuals whose data was used to train the synthetic data generator.  \n",
    "\n",
    "Risk of membership inference can be assessed in multiple scenarios with differing assumptions about what data is available to the attacker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance-based thresholding\n",
    "Choi et al. (2017) and Torfi et al. (2020) calculated the distance between synthetic and real samples. Real samples were derived from the training dataset for the synthetic data generator and from a separate testing set.  Pairwise distances between synthetic and real samples were predicted as a match if the distance was within a specified threshold.  Predictions and labels were then compared to derived performance metrics for the membership inference attack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mi_torfi = pri.membership_inference(mat_f_r_trn=x_trn,\n",
    "                                    mat_f_r_tst=x_tst,\n",
    "                                    mat_f_s=f['x'],\n",
    "                                    header=names,\n",
    "                                    missing_value=missing_value,\n",
    "                                    mi_type='torfi',\n",
    "                                    n_cpu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pri.summarize(res_mi_torfi))\n",
    "res_plt = pri.plot(res_mi_torfi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
