# -*- coding: utf-8 -*-
"""
Description: synthetic eletronic health record data (SEHRD)
Author: Haley Hunter-Zinck
Date: June 23, 2020
"""

from medgan import medgan
#from corgan import corgan
#from medwgan import medwgan
#from ppgan import ppgan

class sehrd(object):
    
    label_medgan = 'medgan'
    label_corgan = 'corgan'
    label_medwgan = 'medwgan'
    label_ppgan = 'ppgan'
    
    def __init__(self):
        self.data = []
        
    """
    def lookup():
        print(label_medgan)
    """
    
    def train(x, method):
        model = None
        
        if method == label_medgan:
            mg = medgan(dataType='binary',
                        inputDim=615,
                        embeddingDim=128,
                        randomDim=128,
                        generatorDims=(128, 128),
                        discriminatorDims=(256, 128, 1),
                        compressDims=(),
                        decompressDims=(),
                        bnDecay=0.99,
                        l2scale=0.001)

            model = mg.train(dataPath=args.data_file,
                             modelPath=args.model_file,
                             outPath=args.out_file,
                             pretrainEpochs=args.n_pretrain_epoch,
                             nEpochs=args.n_epoch,
                             discriminatorTrainPeriod=args.n_discriminator_update,
                             generatorTrainPeriod=args.n_generator_update,
                             pretrainBatchSize=args.pretrain_batch_size,
                             batchSize=args.batch_size,
                             saveMaxKeep=args.save_max_keep)
            
        else:
            print('Method ' + method + ' not recognized.  Returning None.')
        
        return(model)
    
    
    def generate(model, n):
        
        synth = None
        
        if n <= 0:
            print('Number of samples requested (n) must be greater than 0.  Returning None.')
            return(synth)
        
        if method == label_medgan:
            synth = mg.generateData(nSamples=10000,
                        modelFile=args.model_file,
                        batchSize=args.batch_size,
                        outFile=args.out_file)
        else: 
             print('Method ' + method + ' not recognized.  Returning None.')
        
        return(synth)



def parse_arguments(parser):
    parser.add_argument('--embed_size', type=int, default=128, help='The dimension size of the embedding, which will be generated by the generator. (default value: 128)')
    parser.add_argument('--noise_size', type=int, default=128, help='The dimension size of the random noise, on which the generator is conditioned. (default value: 128)')
    parser.add_argument('--generator_size', type=tuple, default=(128, 128), help='The dimension size of the generator. Note that another layer of size "--embed_size" is always added. (default value: (128, 128))')
    parser.add_argument('--discriminator_size', type=tuple, default=(256, 128, 1), help='The dimension size of the discriminator. (default value: (256, 128, 1))')
    parser.add_argument('--compressor_size', type=tuple, default=(), help='The dimension size of the encoder of the autoencoder. Note that another layer of size "--embed_size" is always added. Therefore this can be a blank tuple. (default value: ())')
    parser.add_argument('--decompressor_size', type=tuple, default=(), help='The dimension size of the decoder of the autoencoder. Note that another layer, whose size is equal to the dimension of the <patient_matrix>, is always added. Therefore this can be a blank tuple. (default value: ())')
    parser.add_argument('--data_type', type=str, default='binary', choices=['binary', 'count'], help='The input data type. The <patient matrix> could either contain binary values or count values. (default value: "binary")')
    parser.add_argument('--batchnorm_decay', type=float, default=0.99, help='Decay value for the moving average used in Batch Normalization. (default value: 0.99)')
    parser.add_argument('--L2', type=float, default=0.001, help='L2 regularization coefficient for all weights. (default value: 0.001)')

    parser.add_argument('data_file', type=str, metavar='<patient_matrix>', help='The path to the numpy matrix containing aggregated patient records.')
    parser.add_argument('out_file', type=str, metavar='<out_file>', help='The path to the output models.')
    parser.add_argument('--model_file', type=str, metavar='<model_file>', default='', help='The path to the model file, in case you want to continue training. (default value: '')')
    parser.add_argument('--n_pretrain_epoch', type=int, default=100, help='The number of epochs to pre-train the autoencoder. (default value: 100)')
    parser.add_argument('--n_epoch', type=int, default=1000, help='The number of epochs to train medGAN. (default value: 1000)')
    parser.add_argument('--n_discriminator_update', type=int, default=2, help='The number of times to update the discriminator per epoch. (default value: 2)')
    parser.add_argument('--n_generator_update', type=int, default=1, help='The number of times to update the generator per epoch. (default value: 1)')
    parser.add_argument('--pretrain_batch_size', type=int, default=100, help='The size of a single mini-batch for pre-training the autoencoder. (default value: 100)')
    parser.add_argument('--batch_size', type=int, default=1000, help='The size of a single mini-batch for training medGAN. (default value: 1000)')
    parser.add_argument('--save_max_keep', type=int, default=0, help='The number of models to keep. Setting this to 0 will save models for every epoch. (default value: 0)')
    parser.add_argument('--generate_data', type=str2bool, default=False, help='If True the model generates data, if False the model is trained (default value: False)')
    args = parser.parse_args()
    return args


